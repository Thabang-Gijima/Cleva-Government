import streamlit as sl
import speech_recognition as sr
from deep_translator import GoogleTranslator
from gtts import gTTS
import os
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain.chains import RetrievalQA
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_community.document_loaders import PyPDFLoader
import tiktoken  # Tokenizer library for counting tokens
 
recognizer = sr.Recognizer()
 
sl.markdown("""
<style>
    .title-box {
        background-color: #e0e0e0;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
    }
    .subtitle-box-container {
        display: flex;
        justify-content: space-around;
        margin-top: 20px;
    }
    .subtitle-box {
        flex: 1;
        background-color: #e0e0e0;
        padding: 15px;
        border-radius: 10px;
        margin: 0 10px;
        text-align: center;
        font-weight: bold;
    }
    .response-box {
        background-color: #e0e0e0;
        padding: 15px;
        border-radius: 10px;
        margin-top: 10px;
        border: 1px solid #ddd;
        white-space: pre-wrap;
    }
    .chat-history-box {
        background-color: #f9f9f9;
        padding: 10px;
        border-radius: 5px;
        border: 1px solid #ddd;
        margin-top: 10px;
    }
</style>
""", unsafe_allow_html=True)

def count_tokens(text, model_name="gpt-3.5-turbo"):
    enc = tiktoken.encoding_for_model(model_name)
    tokens = enc.encode(text)
    return len(tokens)

def load_knowledgeBase():
    DB_FAISS_PATH = 'vectorstore/db_faiss'
    embeddings = OpenAIEmbeddings(api_key="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")
    db = FAISS.load_local(DB_FAISS_PATH, embeddings, allow_dangerous_deserialization=True)
    return db

def load_llm():
    from langchain_openai import ChatOpenAI
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0, api_key="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")
    return llm

def load_prompt():
    prompt = """Try to answer the question using the provided context.
    If the context isn't directly relevant or doesn't contain enough information, attempt to answer the question based on general knowledge:
    Context: {context}
    Question: {question}
    """
    prompt = ChatPromptTemplate.from_template(prompt)
    return prompt

def format_docs(docs):
    return " ".join(doc.page_content for doc in docs)

def clean_response(response_text):
    return response_text.replace("\n\n", " ").replace("\n", " ").strip()

def extract_sources(docs):
    sources = set(doc.metadata.get("source", "Unknown") for doc in docs)
    return ", ".join(sources) if sources else "No relevant sources found."

@sl.cache_data
def load_and_index_documents(directory_path):
    all_pages = []
    for filename in os.listdir(directory_path):
        if filename.endswith(".pdf"):
            file_path = os.path.join(directory_path, filename)
            loader = PyPDFLoader(file_path)
            pages = loader.load_and_split()
            all_pages.extend(pages)
            for page in pages:
                page.metadata["source"] = filename
    return all_pages

def process_speech(language_code, use_rag, knowledgeBase, llm, prompt):
    with sr.Microphone() as source:
        sl.write("Please speak something...")
        audio = recognizer.listen(source)

        try:
            speech_text = recognizer.recognize_google(audio, language=language_code)
            sl.write(f"Recognized Speech: {speech_text}")

            if language_code == 'en':
                translated_text = speech_text
            else:
                translated_text = GoogleTranslator(source=language_code, target='en').translate(speech_text)
                sl.write(f"Translated Text: {translated_text}")

            token_count_speech = count_tokens(translated_text)
           
            if use_rag:
                similar_embeddings = knowledgeBase.similarity_search(translated_text)
                if not similar_embeddings:
                    response = llm(translated_text)
                    sources_message = "Response generated by LLM."
                else:
                    context = format_docs(similar_embeddings)
                    prompt_text = prompt.format(context=context, question=translated_text)
                    response = llm.invoke(prompt_text)
                    sources = extract_sources(similar_embeddings)
                    sources_message = f"Referenced Documents: {sources}"
            else:
                response = llm(translated_text)
                sources_message = "Response generated by LLM."

            response_text = response.content if hasattr(response, 'content') else str(response)
            sl.write(f"Response: {response_text}")

            if language_code != 'en':
                translated_back_text = GoogleTranslator(source='en', target=language_code).translate(response_text)
                sl.write(f"Translated Back to {language_code}: {translated_back_text}")
            else:
                translated_back_text = response_text

            tts = gTTS(translated_back_text, lang=language_code)
            audio_file = f"response_{language_code}.mp3"
            tts.save(audio_file)
            sl.audio(audio_file)
           
            token_count_response = count_tokens(translated_back_text)
            total_tokens = token_count_speech + token_count_response
            print(f"Token usage - Speech: {token_count_speech}, Response: {token_count_response}, Total: {total_tokens}")
            print(sources_message)

        except sr.UnknownValueError:
            sl.write("Sorry, I could not understand the audio.")
        except sr.RequestError as e:
            sl.write(f"Could not request results; {e}")
        except Exception as e:
            sl.write(f"An error occurred: {e}")

# Helper function to manage RAG with LLM
def process_rag_query(query, knowledgeBase, llm, prompt):
    similar_embeddings = knowledgeBase.similarity_search(query)
    if not similar_embeddings or len(similar_embeddings) == 0:
        response = llm(query)
        return response.content if hasattr(response, 'content') else str(response), "Generated by LLMs"
    else:
        context = format_docs(similar_embeddings)
        prompt_text = prompt.format(context=context, question=query)
        response = llm.invoke(prompt_text)
        sources = extract_sources(similar_embeddings)
        return response.content if hasattr(response, 'content') else str(response), f"Referenced Documents: {sources}"

if __name__ == '__main__':
    sl.markdown('<div class="title-box"><h1>ClevaGov Chatbot: Guide For Government Regulations</h1></div>', unsafe_allow_html=True)
   
    if "history" not in sl.session_state:
        sl.session_state.history = []
   
    with sl.sidebar:
        sl.title("Chat History")
        for i, (question, response) in enumerate(sl.session_state.history):
            sl.markdown(f"**Q{i+1}:** {question}")
            sl.markdown(f"<div class='chat-history-box'>{response}</div>", unsafe_allow_html=True)
        if sl.button("Start New Chat"):
            sl.session_state.history.clear()

    knowledgeBase = load_knowledgeBase()
    llm = load_llm()
    prompt = load_prompt()

    documents_directory = "./documents"
    load_and_index_documents(documents_directory)

    use_rag = sl.checkbox("Use RAG with LLM", value=True)

    response_text = ""
    query = ""

    input_mode = sl.radio("Choose input mode", ('Text', 'Voice'))

    if input_mode == 'Text':
        query = sl.text_input('Enter your question here')

        if query:
            token_count_prompt = count_tokens(query)
            context_found = False

            if use_rag:
                response_text, sources_message = process_rag_query(query, knowledgeBase, llm, prompt)
            else:
                response = llm(query)
                response_text = response.content if hasattr(response, 'content') else str(response)
                sources_message = "Response generated by LLM."

            response_text = clean_response(response_text)

            sl.markdown(f"<div class='response-box'>{response_text}</div>", unsafe_allow_html=True)

            token_count_response = count_tokens(response_text)
            total_tokens = token_count_prompt + token_count_response
            print(f"Prompt tokens used: {token_count_prompt}")
            print(f"Response tokens used: {token_count_response}")
            print(f"Total token usage: {total_tokens} tokens")

            print(sources_message)

    elif input_mode == 'Voice':
        sl.write("Choose the language to translate from:")
        languages = {
            'English': 'en',
            'Zulu': 'zu',
            'Sotho': 'st',
            'Xhosa': 'xh',
            'Afrikaans': 'af'
        }
        language_choice = sl.selectbox("Select a language", list(languages.keys()))
       
        if sl.button("Record Voice"):
            language_code = languages[language_choice]
            process_speech(language_code, use_rag, knowledgeBase, llm, prompt)

    if query or response_text:
        sl.session_state.history.append((query, response_text))
